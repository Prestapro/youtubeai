import os
import argparse
#
# Attempt to load speaker diarization pipeline
try:
    from pyannote.audio import Pipeline
    HF_TOKEN = os.getenv("HUGGINGFACE_TOKEN")
    if not HF_TOKEN:
        print("‚ö†Ô∏è HUGGINGFACE_TOKEN not set; skipping speaker diarization.")
        diarizer = None
    else:
        try:
            diarizer = Pipeline.from_pretrained(
                "pyannote/speaker-diarization",
                use_auth_token=HF_TOKEN
            )
        except Exception as e:
            print(f"‚ö†Ô∏è Could not load 'pyannote/speaker-diarization' pipeline: {e}")
            print("   Ensure your Hugging Face token has access and retry.")
            diarizer = None
except ImportError:
    print("‚ö†Ô∏è pyannote.audio not installed; skipping speaker diarization.")
    diarizer = None
import nltk
from nltk.tokenize import word_tokenize
from nltk.stem import SnowballStemmer
import pymorphy2
import json
import subprocess
import re
import time
from collections import namedtuple
import ffmpeg

from tqdm import tqdm

# --- –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è video.json –∏ —Å–æ–∑–¥–∞–Ω–∏–µ, –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç ---
if not os.path.exists('video.json'):
    with open('video.json', 'w', encoding='utf-8') as f:
        json.dump({"transcription": []}, f, ensure_ascii=False, indent=4)

# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ –∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è —Å–ª–æ–≤ ---
from datetime import datetime

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ —Å—Ç—Ä–æ–∫–∏ –≤ —Ñ–æ—Ä–º–∞—Ç –≤—Ä–µ–º–µ–Ω–∏
def str_to_time(time_str):
    return datetime.strptime(time_str, "%H:%M:%S,%f")

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è —Å–ª–æ–≤ –∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ—Ä–µ–π–º–æ–≤
def merge_words(word_data):
    """
    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Å–ª–æ–≤–∞ —Å –ø–µ—Ä–µ—Å–µ–∫–∞—é—â–∏–º–∏—Å—è –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞–º–∏.
    –ï—Å–ª–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã –ø–µ—Ä–µ—Å–µ–∫–∞—é—Ç—Å—è –∏–ª–∏ —Å–æ–ø—Ä–∏–∫–∞—Å–∞—é—Ç—Å—è, –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç —Å–ª–æ–≤–∞ –∏ —Ä–∞—Å—à–∏—Ä—è–µ—Ç –∏–Ω—Ç–µ—Ä–≤–∞–ª.
    """
    if not word_data:
        return []
    merged = []
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞—á–∞–ª–∞
    word_data_sorted = sorted(word_data, key=lambda w: str_to_time(w["from"]))
    cur = word_data_sorted[0].copy()
    for word_info in word_data_sorted[1:]:
        prev_to = str_to_time(cur["to"])
        cur_from = str_to_time(cur["from"])
        next_from = str_to_time(word_info["from"])
        next_to = str_to_time(word_info["to"])
        # –ï—Å–ª–∏ –ø–µ—Ä–µ—Å–µ–∫–∞—é—Ç—Å—è –∏–ª–∏ —Å–æ–ø—Ä–∏–∫–∞—Å–∞—é—Ç—Å—è (prev_to >= next_from)
        if prev_to >= next_from:
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å–ª–æ–≤–∞ —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª, —Ä–∞—Å—à–∏—Ä—è–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª
            cur["word"] = cur["word"] + " " + word_info["word"]
            cur["to"] = max(cur["to"], word_info["to"], key=lambda t: str_to_time(t))
        else:
            merged.append(cur)
            cur = word_info.copy()
    merged.append(cur)
    return merged

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∞–π–ª–∞ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏
def generate_timestamp_file(input_file="video.json", output_file="timestamps.json"):
    if not os.path.exists(input_file):
        print(f"–§–∞–π–ª {input_file} –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü—Ä–æ–ø—É—Å–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ timestamps.")
        return

    with open(input_file, "r", encoding="utf-8") as f:
        data = json.load(f)

    print("=== –°–æ–¥–µ—Ä–∂–∏–º–æ–µ video.json ===")
    print(json.dumps(data, ensure_ascii=False, indent=2))

    timestamps = []
    # –ù–æ–≤—ã–π —Å–ø–æ—Å–æ–±: –∏—Ç–µ—Ä–∏—Ä—É–µ–º –ø–æ data['segments'][*]['words']
    for segment in data.get('segments', []):
        for item in segment.get('words', []):
            word = item['word'].strip()
            if word.isalpha() and len(word) > 1:
                normal_form = morph.parse(word)[0].normal_form
                time_from = format_time(item['start'])
                time_to = format_time(item['end'])
                timestamps.append({
                    'word': normal_form,
                    'from': time_from,
                    'to': time_to
                })

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —Å–ª–æ–≤ —Å –ø–µ—Ä–µ–∫—Ä—ã–≤–∞—é—â–∏–º–∏—Å—è –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞–º–∏
    merged_timestamps = merge_words(timestamps)

    # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    unique_timestamps = []
    seen_keys = set()
    for item in merged_timestamps:
        key = f"{item['word']}_{item['from']}_{item['to']}"
        if key not in seen_keys:
            seen_keys.add(key)
            unique_timestamps.append(item)

    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(unique_timestamps, f, ensure_ascii=False, indent=4)

    print(f"–¢–∞–π–º–∫–æ–¥—ã –∏ —Å–ª–æ–≤–∞ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_file}")
    print(f"–û–±—ä–µ–¥–∏–Ω–µ–Ω–æ {len(timestamps)} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –≤ {len(unique_timestamps)} —Å–ª–æ–≤")

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫ –ø–æ —Å–ª–æ–≤–∞–º
def adjust_timestamps_for_words(data):
    for i in range(len(data)):
        start = data[i]['timestamps']['from']
        end = data[i]['timestamps']['to']
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –ª–æ–≥–∏–∫—É –¥–ª—è —Å–ª–æ–≤
        word = data[i]['text'].strip()
        if word:
            data[i]['timestamps']['from'] = start
            data[i]['timestamps']['to'] = end
    return data


# --- –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ü–µ–ª—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π ---
def extract_full_sentences(transcript):
    sentence_endings = r'([.!?])'
    sentences = re.split(sentence_endings, transcript)
    full_sentences = []

    for i in range(0, len(sentences)-1, 2):
        sentence = sentences[i].strip() + sentences[i+1].strip()
        if sentence:
            full_sentences.append(sentence)

    return full_sentences

# --- –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –≤ video.json ---
def save_to_json(data, filename="video.json"):
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=4)
#
# --- Python 3.11 compat: restore inspect.getargspec for pymorphy2 ---
import inspect
if not hasattr(inspect, "getargspec"):
    def _getargspec(func):
        sig = inspect.signature(func)
        args, defaults = [], []
        varargs = varkw = None
        for p in sig.parameters.values():
            if p.kind in (
                inspect.Parameter.POSITIONAL_ONLY,
                inspect.Parameter.POSITIONAL_OR_KEYWORD,
            ):
                args.append(p.name)
                if p.default is not inspect.Parameter.empty:
                    defaults.append(p.default)
            elif p.kind == inspect.Parameter.VAR_POSITIONAL:
                varargs = p.name
            elif p.kind == inspect.Parameter.VAR_KEYWORD:
                varkw = p.name
        ArgSpec = namedtuple("ArgSpec", "args varargs keywords defaults")
        return ArgSpec(args, varargs, varkw,
                       tuple(defaults) if defaults else None)
    inspect.getargspec = _getargspec
# -------------------------------------------------------------------

#
# Ensure nltk punkt is downloaded and stemmer is available
nltk.download('punkt')
try:
    stemmer_ru = SnowballStemmer("russian")
    stemmer_en = SnowballStemmer("english")
except:
    nltk.download('punkt')
    stemmer_ru = SnowballStemmer("russian")
    stemmer_en = SnowballStemmer("english")

morph = pymorphy2.MorphAnalyzer()

# whisper.cpp config
WHISPER_CPP_BIN = "./whisper.cpp/main"
WHISPER_CPP_MODEL = "./whisper.cpp/models/ggml-large-v3.bin"
VIDEO_FILE = "audio.mp4"

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –≤—Ä–µ–º–µ–Ω–∏ –≤ —Ñ–æ—Ä–º–∞—Ç SRT
def format_time(seconds):
    h, rem = divmod(seconds, 3600)
    m, s = divmod(rem, 60)
    return f"{int(h):02}:{int(m):02}:{int(s):02},{int((s - int(s)) * 1000):03}"

# –§–∞–π–ª –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤–∏–¥–µ–æ
VIDEO_FILE = "audio.mp4"

def download_audio_from_youtube(url):
    start_time = time.time()
    subprocess.run([
        "yt-dlp", "--cookies-from-browser", "chrome",
        "-f", "bestvideo+bestaudio",
        "-o", VIDEO_FILE,
        url
    ])

# --- Download audio only for fast transcription ---
def download_audio_only(youtube_url, output_path):
    """
    –°–∫–∞—á–∞—Ç—å —Ç–æ–ª—å–∫–æ –∞—É–¥–∏–æ-–¥–æ—Ä–æ–∂–∫—É –∏–∑ YouTube –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–Ω–æ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –≤ WAV.
    """
    cmd = [
        "yt-dlp",
        "--cookies-from-browser", "chrome",
        "-x",
        "--audio-format", "wav",
        "-f", "bestaudio",
        "-o", output_path,
        youtube_url
    ]
    subprocess.run(cmd, check=True)

def tokenize_words_only(data):
    result = []
    for item in data:
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å–ª–æ–≤–∞
        tokens = word_tokenize(item["text"], language="russian")
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å–ª–æ–≤–∞, –ø–æ–ª—É—á–∞—è –∏—Ö –ª–µ–º–º—ã
        words = [morph.parse(token)[0].normal_form for token in tokens if token.isalpha() and len(token) > 1]
        result.extend(words)
    return result

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ –∏ —Å–æ–∑–¥–∞–Ω–∏—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞ —Å –ø–æ–º–æ—â—å—é whisper.cpp, —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ video.json

from faster_whisper import WhisperModel

def download_audio(youtube_url, output_path):
    # –°–∫–∞—á–∏–≤–∞–µ–º –ø–æ–ª–Ω—ã–π –≤–∏–¥–µ–æ—Ñ–∞–π–ª (–≤–∏–¥–µ–æ+–∞—É–¥–∏–æ) –¥–ª—è –Ω–∞—Ä–µ–∑–∫–∏
    cmd = [
        "yt-dlp",
        "--cookies-from-browser", "chrome",
        "-f", "bestvideo[ext=mp4]+bestaudio[ext=m4a]",
        "--merge-output-format", "mp4",
        "-o", output_path,
        youtube_url
    ]
    subprocess.run(cmd, check=True)

def transcribe_audio(audio_path):
    print("üì• –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å Faster-Whisper...")
    # –ü–æ–¥–±–æ—Ä —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞: MPS –Ω–∞ macOS (Apple Silicon), –∏–Ω–∞—á–µ CPU
    try:
        import torch
        device = "mps" if torch.backends.mps.is_available() else "cpu"
    except ImportError:
        device = "cpu"
    print(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: {device}")
    model = WhisperModel("medium", device=device, compute_type="int8")
    print("üß† –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º –∞—É–¥–∏–æ (c word_timestamps)...")
    segments, info = model.transcribe(audio_path, beam_size=1, word_timestamps=True)
    segments = list(segments)
    print(f"‚úÖ –Ø–∑—ã–∫: {info.language}, –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {info.duration:.2f} —Å–µ–∫")

    # –í—ã–ø–æ–ª–Ω—è–µ–º –¥–∏–∞—Ä–∏–∑–∞—Ü–∏—é
    if diarizer:
        print("üéôÔ∏è –í—ã–ø–æ–ª–Ω—è–µ–º –¥–∏–∞—Ä–∏–∑–∞—Ü–∏—é —Å–ø–∏–∫–µ—Ä–æ–≤...")
        diarization = diarizer(audio_path)
    else:
        diarization = []

    result = {"text": "", "segments": [], "language": info.language}
    for i, segment in enumerate(segments):
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–ø–∏–∫–µ—Ä–∞ –ø–æ –Ω–∞—á–∞–ª—É —Å–µ–≥–º–µ–Ω—Ç–∞
        speaker_label = None
        if diarizer:
            for turn, _, speaker in diarization.itertracks(yield_label=True):
                if segment.start >= turn.start and segment.start < turn.end:
                    speaker_label = speaker
                    break
        else:
            # Fallback: alternate speakers if no diarization available
            speaker_label = f"speaker_{i % 2}"

        seg_data = {
            "id": i,
            "speaker": speaker_label or "Unknown",
            "start": segment.start,
            "end": segment.end,
            "text": segment.text,
            "words": [
                {"word": w.word, "start": w.start, "end": w.end}
                for w in (segment.words or [])
            ]
        }
        result["segments"].append(seg_data)
        # Append each speaker segment on its own line
        result["text"] += f"{speaker_label or 'Unknown'}: {segment.text}\n"

    return result

def print_word_timestamps(transcription):
    for segment in tqdm(transcription['segments'], desc="‚è± –°–µ–≥–º–µ–Ω—Ç—ã"):
        for word_info in segment.get('words', []):
            word = word_info['word']
            start_time = word_info['start']
            print(f"{word} [{start_time:.2f}s]")


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –Ω–∞—Ä–µ–∑–∫–∏ –∫–ª–∏–ø–æ–≤ (–≤–∏–¥–µ–æ+–∞—É–¥–∏–æ)
def extract_clips(audio_file, segments, video_file="audio.mp4"):
    start_time_total = time.time()
    start_time_cut = time.time()
    for idx, (start, end) in enumerate(tqdm(segments, desc="üéû –ù–∞—Ä–µ–∑–∫–∞ –∫–ª–∏–ø–æ–≤"), 1):
        safe_start = format_time(start).replace(",", "_").replace(":", "_")
        safe_end = format_time(end).replace(",", "_").replace(":", "_")
        output_filename = f"clip_{idx}_{safe_start}_{safe_end}.mp4"
        try:
            # –î–æ–±–∞–≤–ª—è–µ–º drawtext —Ñ–∏–ª—å—Ç—Ä —Å —Ç–∞–π–º–∫–æ–¥–æ–º –≤ –ø—Ä–∞–≤–æ–º –Ω–∏–∂–Ω–µ–º —É–≥–ª—É
            timestamp = f"{int(start // 60):02}\\:{int(start % 60):02}"
            (
                ffmpeg
                .input(video_file, ss=start)
                .output(
                    output_filename,
                    vf=f"drawtext=fontfile=/System/Library/Fonts/SFNSDisplay.ttf:text='{timestamp}':x=w-tw-10:y=h-th-10:fontsize=24:fontcolor=white:borderw=2",
                    vcodec="libx264",
                    acodec="aac",
                    audio_bitrate="192k",
                    format="mp4",
                    t=end - start,
                    **{'metadata': 'timecode=00:00:00:00'}
                )
                .overwrite_output()
                .run(quiet=False)
            )
            print(f"–°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª: {output_filename}")
        except ffmpeg.Error as e:
            if e.stderr is not None:
                try:
                    error_message = e.stderr.decode()
                except Exception:
                    error_message = str(e)
            else:
                error_message = str(e)
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –Ω–∞—Ä–µ–∑–∫–µ —Ñ–∞–π–ª–∞ {output_filename}: {error_message}")
    cut_time = time.time() - start_time_cut
    print(f"‚è± –ù–∞—Ä–µ–∑–∫–∞ –∑–∞–Ω—è–ª–∞ {cut_time:.2f} —Å–µ–∫—É–Ω–¥")
    log_time("–ù–∞—Ä–µ–∑–∫–∞ –∫–ª–∏–ø–æ–≤", start_time_cut)

    # –°–∫–ª–µ–∏–≤–∞–µ–º –≤—Å–µ –∫–ª–∏–ø—ã –≤ –æ–¥–∏–Ω —Ñ–∞–π–ª —Å –ø–æ–º–æ—â—å—é ffmpeg concat –∏ -c copy
    # –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –Ω–∞–∑–≤–∞–Ω–∏–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤
    final_clips = []
    for idx in range(1, len(segments) + 1):
        start_fmt = format_time(segments[idx - 1][0]).replace(",", "_").replace(":", "_")
        end_fmt = format_time(segments[idx - 1][1]).replace(",", "_").replace(":", "_")
        clip_name = f"clip_{idx}_{start_fmt}_{end_fmt}.mp4"
        final_clips.append(clip_name)

    # –§–∏–ª—å—Ç—Ä—É–µ–º –Ω–µ–ø—É—Å—Ç—ã–µ —Ñ–∞–π–ª—ã (—Ä–∞–∑–º–µ—Ä –±–æ–ª—å—à–µ 2–ö–ë)
    final_clips = [f for f in final_clips if os.path.exists(f) and os.path.getsize(f) > 2048]

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª list.txt —Å–æ —Å–ø–∏—Å–∫–æ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤
    with open("list.txt", "w") as f:
        for filename in final_clips:
            f.write(f"file '{filename}'\n")

    # –°–∫–ª–µ–π–∫–∞ —Å –ø–æ–º–æ—â—å—é ffmpeg-python
    try:
        (
            ffmpeg
            .input('list.txt', format='concat', safe=0)
            .output('final.mp4', c='copy')
            .run(overwrite_output=True)
        )
        print("‚úÖ –°–∫–ª–µ–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω –∫–∞–∫ final.mp4")
        log_time("–°–∫–ª–µ–π–∫–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞", start_time_total)
    except ffmpeg.Error as e:
        if e.stderr is not None:
            try:
                error_message = e.stderr.decode()
            except Exception:
                error_message = str(e)
        else:
            error_message = str(e)
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–ª–µ–π–∫–µ –∫–ª–∏–ø–æ–≤: {error_message}")
# –£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏ —ç—Ç–∞–ø–æ–≤

def log_time(stage, start_time):
    elapsed_time = time.time() - start_time
    print(f"‚è± {stage} –∑–∞–Ω—è–ª–æ {elapsed_time:.2f} —Å–µ–∫—É–Ω–¥")

#
# --- Add extract_by_keyword function ---
def extract_by_keyword(
    keyword,
    video_json="video.json",
    audio_file="audio.mp3",
    video_file="audio.mp3",
    allow_partial=False,
    padding_before=1.0,
    padding_after=1.0
):
    # now supports custom padding before/after each segment
    with open(video_json, "r", encoding="utf-8") as f:
        data = json.load(f)

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —è–∑—ã–∫ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é
    lang = data.get("language", "en")
    if lang == "ru":
        normalize = lambda w: morph.parse(w)[0].normal_form
    else:
        normalize = lambda w: stemmer_en.stem(w.lower())

    target_segments = []

    # Multi-word phrase normalization
    phrase_tokens = [normalize(re.sub(r"[^\w—ë–Å–∞-—è–ê-–Øa-zA-Z]", "", w)) for w in keyword.split() if w.strip()]
    phrase_length = len(phrase_tokens)

    print(f"[DEBUG] phrase_tokens: {phrase_tokens}")

    for segment in tqdm(data.get("segments", []), desc="üîç –ü–æ–∏—Å–∫ —Ñ—Ä–∞–∑—ã"):
        words = segment.get("words", [])
        print(f"üìã –°–µ–≥–º–µ–Ω—Ç: {segment.get('text', '')[:50]}...")
        norm_words = []
        if words:
            for word_info in words:
                raw = word_info.get("word", "").strip()
                if not raw:
                    continue
                cleaned = re.sub(r"[^\w—ë–Å–∞-—è–ê-–Øa-zA-Z]", "", raw.lower())
                if not cleaned:
                    continue
                try:
                    norm = normalize(cleaned)
                except Exception as e:
                    print(f"[WARN] Can't normalize '{cleaned}': {e}")
                    continue
                norm_words.append((norm, word_info["start"], word_info["end"]))
        else:
            print("[DEBUG] –ü—Ä–æ–ø—É—â–µ–Ω —Å–µ–≥–º–µ–Ω—Ç –±–µ–∑ words")
            continue
        print(f"[DEBUG] norm_words: {norm_words}")

        for i in range(len(norm_words) - phrase_length + 1):
            window = norm_words[i:i+phrase_length]
            print(f"[DEBUG] Checking window: {[w[0] for w in window]} vs {phrase_tokens}")
            if all(
                (p == w[0]) or (
                    allow_partial
                    and len(p) >= 3
                    and (w[0].startswith(p) or w[0].endswith(p))
                )
                for p, w in zip(phrase_tokens, window)
            ):
                start = max(0, window[0][1] - padding_before)
                end = window[-1][2] + padding_after
                print(f"üîé –ù–∞–π–¥–µ–Ω–∞ —Ñ—Ä–∞–∑–∞ –Ω–∞ {start:.2f}s ‚Äì {end:.2f}s")
                target_segments.append((start, end))

    # Merge overlapping or adjacent segments to avoid duplicates
    target_segments.sort(key=lambda x: x[0])
    merged_segments = []
    for start, end in target_segments:
        if not merged_segments:
            merged_segments.append((start, end))
        else:
            prev_start, prev_end = merged_segments[-1]
            if start <= prev_end:
                # Overlaps or adjacent: extend the previous segment
                merged_segments[-1] = (prev_start, max(prev_end, end))
            else:
                merged_segments.append((start, end))
    target_segments = merged_segments

    # Merge overlapping or adjacent segments to avoid duplicates
    target_segments.sort(key=lambda x: x[0])
    merged_segments = []
    for start, end in target_segments:
        if not merged_segments:
            merged_segments.append((start, end))
        else:
            prev_start, prev_end = merged_segments[-1]
            if start <= prev_end:
                # Overlaps or adjacent: extend the previous segment
                merged_segments[-1] = (prev_start, max(prev_end, end))
            else:
                merged_segments.append((start, end))
    target_segments = merged_segments

    if not target_segments:
        print(f"–§—Ä–∞–∑–∞ '{keyword}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
        return

    print(
        f"–ù–∞–π–¥–µ–Ω–æ {len(target_segments)} –≤—Ö–æ–∂–¥–µ–Ω–∏–π —Ñ—Ä–∞–∑—ã '{keyword}'"
        + (" (—á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ)" if allow_partial else "")
    )
    extract_clips(audio_file, target_segments, video_file=video_file)

# --- –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ, –æ–±—Ä–∞–±–æ—Ç–∫–∞, —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è ---
def generate_timestamp_file(input_file="video.json", output_file="timestamps.json"):
    if not os.path.exists(input_file):
        print(f"–§–∞–π–ª {input_file} –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü—Ä–æ–ø—É—Å–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ timestamps.")
        return

    with open(input_file, "r", encoding="utf-8") as f:
        data = json.load(f)

    timestamps = []
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ —Å–ª–æ–≤–∞ –∏–∑ –±—É–∫–≤, –¥–ª–∏–Ω–æ–π –±–æ–ª—å—à–µ 1 —Å–∏–º–≤–æ–ª–∞, –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º
    for item in data['transcription']:
        word = item['text'].strip()
        if word.isalpha() and len(word) > 1:
            normal_form = morph.parse(word)[0].normal_form
            time_from = item['timestamps']['from']
            time_to = item['timestamps']['to']
            timestamps.append({
                'word': normal_form,
                'from': time_from,
                'to': time_to
            })

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —Å–ª–æ–≤ —Å –ø–µ—Ä–µ–∫—Ä—ã–≤–∞—é—â–∏–º–∏—Å—è –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞–º–∏
    merged_timestamps = merge_words(timestamps)

    # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    unique_timestamps = []
    seen_keys = set()
    for item in merged_timestamps:
        key = f"{item['word']}_{item['from']}_{item['to']}"
        if key not in seen_keys:
            seen_keys.add(key)
            unique_timestamps.append(item)

    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(unique_timestamps, f, ensure_ascii=False, indent=4)

    print(f"–¢–∞–π–º–∫–æ–¥—ã –∏ —Å–ª–æ–≤–∞ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_file}")
    print(f"–û–±—ä–µ–¥–∏–Ω–µ–Ω–æ {len(timestamps)} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –≤ {len(unique_timestamps)} —Å–ª–æ–≤")
    # (Repeated block removed.)

nltk.download('punkt')
try:
    stemmer = SnowballStemmer("russian")
except:
    nltk.download('punkt')
    stemmer = SnowballStemmer("russian")

morph = pymorphy2.MorphAnalyzer()

WHISPER_CPP_BIN = "./whisper.cpp/main"
WHISPER_CPP_MODEL = "./whisper.cpp/models/ggml-large-v3.bin"
VIDEO_FILE = "audio.mp4"

def format_time(seconds):
    m, s = divmod(seconds, 60)
    return f"{int(m):02}:{int(s):02},{int((s - int(s)) * 1000):03}"

def download_audio_from_youtube(url):
    start_time = time.time()
    subprocess.run([
        "yt-dlp", "--cookies-from-browser", "chrome",
        "-f", "bestvideo+bestaudio",
        "-o", VIDEO_FILE,
        url
    ])

def tokenize_words_only(data):
    result = []
    for item in data:
        tokens = word_tokenize(item["text"], language="russian")
        words = [morph.parse(token)[0].normal_form for token in tokens if token.isalpha() and len(token) > 1]
        result.extend(words)
    return result

def extract_clips(audio_file, segments, video_file="audio.mp4"):
    start_time_total = time.time()
    start_time_cut = time.time()
    total_segments = len(segments)
    print(f"üîç –í—Å–µ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {total_segments}")
    for idx, (start, end) in enumerate(segments, 1):
        if end - start < 0.3:
            print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω —Å–µ–≥–º–µ–Ω—Ç {idx}: –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–ª–∏—à–∫–æ–º –º–∞–ª–∞ ({end - start:.2f} —Å–µ–∫)")
            continue
        if not os.path.exists(video_file):
            print(f"üö´ –§–∞–π–ª {video_file} –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü—Ä–æ–ø—É—Å–∫ —Å–µ–≥–º–µ–Ω—Ç–∞ {idx}.")
            continue
        print(f"[DEBUG] –°–µ–≥–º–µ–Ω—Ç {idx}: start={start:.2f}, end={end:.2f}, –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å={end - start:.2f}")
        safe_start = format_time(start).replace(",", "_").replace(":", "_")
        safe_end = format_time(end).replace(",", "_").replace(":", "_")
        output_filename = f"clip_{idx}_{safe_start}_{safe_end}.mp4"
        print(f"[DEBUG] –ö–ª–∏–ø {idx}: {start:.2f}s ‚Äì {end:.2f}s ({end - start:.2f}s)")
        try:
            # Human-readable timestamp HH:MM:SS
            hours = int(start // 3600)
            mins = int((start % 3600) // 60)
            secs = int(start % 60)
            timestamp = f"{hours:02}\\:{mins:02}\\:{secs:02}"
            counter = f"{idx}/{total_segments}"
            (
                ffmpeg
                .input(video_file, ss=start)
                .output(
                    output_filename,
                    vf=f"drawtext=fontfile=/System/Library/Fonts/SFNSDisplay.ttf:text='{timestamp} {counter}':x=w-tw-10:y=h-th-10:fontsize=24:fontcolor=white:borderw=2",
                    vcodec="libx264",
                    acodec="aac",
                    audio_bitrate="192k",
                    format="mp4",
                    t=end - start,
                    **{'metadata': 'timecode=00:00:00:00'}
                )
                .run(overwrite_output=True, capture_stdout=True, capture_stderr=True)
            )
            if os.path.exists(output_filename) and os.path.getsize(output_filename) < 2048:
                print(f"[WARNING] –ö–ª–∏–ø {output_filename} —Å–ª–∏—à–∫–æ–º –º–∞–ª: {os.path.getsize(output_filename)} –±–∞–π—Ç")
            print(f"–°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª: {output_filename}")
        except ffmpeg.Error as e:
            if e.stderr is not None:
                print(f"[FFmpeg ERROR] –°–µ–≥–º–µ–Ω—Ç {idx}:")
                try:
                    error_message = e.stderr.decode()
                except Exception:
                    error_message = str(e)
            else:
                error_message = str(e)
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –Ω–∞—Ä–µ–∑–∫–µ —Ñ–∞–π–ª–∞ {output_filename}: {error_message}")
            print("üö´ FFmpeg stderr:")
            print(error_message)
    cut_time = time.time() - start_time_cut
    print(f"‚è± –ù–∞—Ä–µ–∑–∫–∞ –∑–∞–Ω—è–ª–∞ {cut_time:.2f} —Å–µ–∫—É–Ω–¥")
    log_time("–ù–∞—Ä–µ–∑–∫–∞ –∫–ª–∏–ø–æ–≤", start_time_cut)

    final_clips = []
    for idx, (start, end) in enumerate(segments, 1):
        if end - start < 0.3:
            continue
        start_fmt = format_time(start).replace(",", "_").replace(":", "_")
        end_fmt = format_time(end).replace(",", "_").replace(":", "_")
        clip_name = f"clip_{idx}_{start_fmt}_{end_fmt}.mp4"
        if os.path.exists(clip_name) and os.path.getsize(clip_name) > 2048:
            final_clips.append(clip_name)

    with open("list.txt", "w") as f:
        for filename in final_clips:
            f.write(f"file '{filename}'\n")

    if not final_clips:
        print("‚ö†Ô∏è –ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –∫–ª–∏–ø–æ–≤ –¥–ª—è —Å–∫–ª–µ–π–∫–∏. –ü—Ä–æ–ø—É—Å–∫ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è.")
        if os.path.exists("list.txt"):
            os.remove("list.txt")
        return

    try:
        (
            ffmpeg
            .input('list.txt', format='concat', safe=0)
            .output('final.mp4', c='copy')
            .run(overwrite_output=True)
        )
        print("‚úÖ –°–∫–ª–µ–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω –∫–∞–∫ final.mp4")
        log_time("–°–∫–ª–µ–π–∫–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞", start_time_total)
    except ffmpeg.Error as e:
        if e.stderr is not None:
            try:
                error_message = e.stderr.decode()
            except Exception:
                error_message = str(e)
        else:
            error_message = str(e)
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–ª–µ–π–∫–µ –∫–ª–∏–ø–æ–≤: {error_message}")
    # –£–¥–∞–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ list.txt
    if os.path.exists("list.txt"):
        os.remove("list.txt")

def log_time(stage, start_time):
    elapsed_time = time.time() - start_time
    print(f"‚è± {stage} –∑–∞–Ω—è–ª–æ {elapsed_time:.2f} —Å–µ–∫—É–Ω–¥")

def main():
    parser = argparse.ArgumentParser(description="Extract clips from YouTube video by keywords.")
    parser.add_argument("--video", type=str, required=True, help="YouTube video URL")
    parser.add_argument("--keywords", type=str, required=True, help="–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é")
    parser.add_argument("--partial", action="store_true",
                        help="–†–∞–∑—Ä–µ—à–∏—Ç—å —á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å–ª–æ–≤ (–ø—Ä–∏–º–µ—Ä = –Ω–∞–ø—Ä–∏–º–µ—Ä), –Ω–æ –Ω–µ –ø–æ–¥—Å—Ç—Ä–æ–∫–∏ (–º–∏—Ä ‚â† –º–∏—Ä–æ–µ–¥)")
    parser.add_argument(
        "--padding-before", type=float, default=1.0,
        help="–°–µ–∫—É–Ω–¥ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ø–µ—Ä–µ–¥ –Ω–∞–π–¥–µ–Ω–Ω—ã–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–º (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1.0)"
    )
    parser.add_argument(
        "--padding-after", type=float, default=1.0,
        help="–°–µ–∫—É–Ω–¥ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ø–æ—Å–ª–µ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1.0)"
    )
    parser.add_argument(
        "--keep-clips", action="store_true",
        help="–ù–µ —É–¥–∞–ª—è—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–µ –∫–ª–∏–ø—ã –ø–æ—Å–ª–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –≤ final.mp4 (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∫–ª–∏–ø—ã —É–¥–∞–ª—è—é—Ç—Å—è)"
    )
    parser.add_argument(
        "--download-video", action="store_true",
        help="–°–æ—Ö—Ä–∞–Ω—è—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –≤–∏–¥–µ–æ—Ñ–∞–π–ª –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —É–¥–∞–ª—è–µ—Ç—Å—è)"
    )
    args = parser.parse_args()
    # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–π JSON, —á—Ç–æ–±—ã –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –¥–∞–Ω–Ω—ã–µ
    if os.path.exists("video.json"):
        os.remove("video.json")

    youtube_spec = os.path.expanduser(args.video)
    keywords = [w.strip() for w in args.keywords.split(",") if w.strip()]
    if not keywords:
        print("–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –Ω–µ –≤–≤–µ–¥–µ–Ω—ã. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ.")
        return

    youtube_spec = os.path.expanduser(args.video)
    if os.path.exists(youtube_spec):
        audio_file = video_file = youtube_spec
        downloaded = False
    else:
        # –°–∫–∞—á–∏–≤–∞–µ–º –∞—É–¥–∏–æ –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
        audio_file = "audio.wav"
        print("üîª –°–∫–∞—á–∏–≤–∞–µ–º –∞—É–¥–∏–æ –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏...")
        download_audio_only(args.video, audio_file)
        # –°–∫–∞—á–∏–≤–∞–µ–º –≤–∏–¥–µ–æ+–∞—É–¥–∏–æ, –µ—Å–ª–∏ –Ω—É–∂–µ–Ω –æ—Ä–∏–≥–∏–Ω–∞–ª
        if args.download_video:
            video_file = "video.mp4"
            print("üîª –°–∫–∞—á–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª –≤–∏–¥–µ–æ+–∞—É–¥–∏–æ –≤ video.mp4...")
            download_audio(args.video, video_file)
        else:
            video_file = audio_file
        downloaded = True

    print("üß† –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏...")
    transcription = transcribe_audio(audio_file)

    print("üïí –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å —Ç–∞–π–º–∫–æ–¥–∞–º–∏:")
    print_word_timestamps(transcription)

    print("üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ video.json...")
    with open("video.json", "w", encoding="utf-8") as f:
        json.dump(transcription, f, ensure_ascii=False, indent=4)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ —Å –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∏–º–µ–Ω–∏
    base_name = "transcript"
    ext = ".txt"
    file_name = base_name + ext
    counter = 1
    while os.path.exists(file_name):
        file_name = f"{base_name}_{counter}{ext}"
        counter += 1
    print(f"üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –≤ {file_name}...")
    with open(file_name, "w", encoding="utf-8") as f:
        f.write(transcription.get("text", "").strip())

    for keyword in keywords:
        print(f"üéØ –ü–æ–∏—Å–∫ –∫–ª—é—á–µ–≤–æ–π —Ñ—Ä–∞–∑—ã –∏ –Ω–∞—Ä–µ–∑–∫–∞ –∫–ª–∏–ø–æ–≤ –¥–ª—è '{keyword}'...")
        extract_by_keyword(
            keyword,
            audio_file=audio_file,
            video_file=video_file,
            allow_partial=args.partial,
            padding_before=args.padding_before,
            padding_after=args.padding_after
        )
        if not args.keep_clips:
            import glob
            for clip_file in glob.glob("clip_*.mp4"):
                if os.path.basename(clip_file) != "final.mp4":
                    os.remove(clip_file)
            print("üóëÔ∏è –£–¥–∞–ª–µ–Ω—ã –æ—Ç–¥–µ–ª—å–Ω—ã–µ –∫–ª–∏–ø—ã, –æ—Å—Ç–∞–≤–ª–µ–Ω —Ç–æ–ª—å–∫–æ final.mp4")

    # Clean up downloaded file if needed
    if downloaded:
        if not args.download_video:
            print("üßπ –£–¥–∞–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –≤–∏–¥–µ–æ—Ñ–∞–π–ª–∞...")
            os.remove(video_file)
        else:
            print(f"üíæ –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –≤–∏–¥–µ–æ—Ñ–∞–π–ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω –∫–∞–∫ {video_file}")

if __name__ == "__main__":
    main()
